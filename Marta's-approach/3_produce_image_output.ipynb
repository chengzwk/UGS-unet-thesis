{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxcP-IHkDj6E"
      },
      "source": [
        "This script produces public urban green spaces prediction based on sattelite image and previously created model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvvz8d3iP1G"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation_models\n",
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from patchify import patchify, unpatchify\n",
        "from keras.models import load_model\n",
        "import segmentation_models as sm\n",
        "import gdal, ogr, os, osr\n",
        "\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import MeanIoU"
      ],
      "metadata": {
        "id": "7dZAPV4Nk4QB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29095458-e697-49e8-f3b9-d8fd7439fc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g2tzIbWDm0v",
        "outputId": "11430660-b3f1-431e-9326-2a3454aad3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connecting to the Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load image file for a prediction city"
      ],
      "metadata": {
        "id": "BAP1HZA5Ka7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_file_to_array(city):  \n",
        "  '''  read the satellite image file   '''\n",
        " \n",
        "  image_file_path = os.path.join(dir, city, image_file_name)\n",
        "  image = gdal.Open(image_file_path)\n",
        "  image_array = image.ReadAsArray()\n",
        "  image_array = np.transpose(image_array, [1, 2, 0])  # transpose the first and third axis\n",
        "\n",
        "  return image_array"
      ],
      "metadata": {
        "id": "EQTYwRvhmFia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the directory and file \n",
        "dir = #location of main folder\n",
        "image_file_name = 'image_bgr_nir_ndvi_landcover_ndbi_ndwi.tif'\n",
        "\n",
        "city =  \"Washington\" \n",
        "\n",
        "image_array = image_file_to_array(city)"
      ],
      "metadata": {
        "id": "_hr7cNtKmI04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr8PMx0e-QeT"
      },
      "outputs": [],
      "source": [
        "#chips 3 [2,3,4]\n",
        "image_array = image_array[:,:,[2,3,4]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wclPjSD8mOKQ",
        "outputId": "5396f2e3-4b66-403c-bcbc-b440fffa98cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2082, 1811, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the prediction model"
      ],
      "metadata": {
        "id": "eEDiyxYiKfTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeUpWxwoFGaK"
      },
      "outputs": [],
      "source": [
        "model_test = load_model('model location', compile = False)\n",
        "\n",
        "model_test.compile(optimizer=Adam(learning_rate = 1e-4), loss = sm.losses.binary_focal_dice_loss, \n",
        "              metrics=['accuracy', sm.metrics.IOUScore(threshold=0.5), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]) # use the same parameters as in original training!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chip image and predict on each chip"
      ],
      "metadata": {
        "id": "caEK-G4eKvEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yXRATdPElXK"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "img_patches = patchify(image_array, (256, 256, image_array.shape[2]), step=256)\n",
        "predicted_patches = []  # initialise output\n",
        "for i in range(img_patches.shape[0]):\n",
        "    for j in range(img_patches.shape[1]):\n",
        "      single_patch_img = img_patches[i, j, 0, :, :, :]\n",
        "      single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "      single_patch_img = np.expand_dims(single_patch_img, axis = 0)  # expand dimension to fit the shape of training data of loaded_model\n",
        "      pred = model_test.predict(single_patch_img)  # make prediction on single patch\n",
        "      pred_argmax = np.argmax(pred, axis = 3)  # get the max value in axis = 3, need to do this because we are using one-hot encoding\n",
        "      pred_argmax = np.expand_dims(pred_argmax, axis = 3)[0, :, :, :]  # expand dimension to fit shape\n",
        "      predicted_patches.append(pred_argmax)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn list into array\n",
        "predicted_patches = np.array(predicted_patches)\n",
        "\n",
        "# reshape array for unpatchify\n",
        "predicted_patches_reshaped = predicted_patches.reshape((img_patches.shape[0], img_patches.shape[1], 256, 256, 1))\n",
        "predicted_patches_reshaped = predicted_patches_reshaped[:, :, :, :, 0]  # to fit shape for unpatchify\n"
      ],
      "metadata": {
        "id": "JHy9ILNNksF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge chips together (unpatchify)\n",
        "reconstructed_image = unpatchify(predicted_patches_reshaped, (256*img_patches.shape[0], 256*img_patches.shape[1]))"
      ],
      "metadata": {
        "id": "026Dbad4nk6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predicted array into tiff file\n",
        "# function to turn array into tiff file with metadata\n",
        "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array):\n",
        "    cols = array.shape[1]\n",
        "    rows = array.shape[0]\n",
        "    originX = rasterOrigin[0]\n",
        "    originY = rasterOrigin[1]\n",
        "\n",
        "    driver = gdal.GetDriverByName('GTiff')\n",
        "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)\n",
        "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
        "    outband = outRaster.GetRasterBand(1)\n",
        "    outband.WriteArray(array)\n",
        "    outRasterSRS = osr.SpatialReference()\n",
        "    outRasterSRS.ImportFromEPSG(32636)  # set epsg you want\n",
        "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
        "    outband.FlushCache()\n",
        "\n",
        "def main(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array):\n",
        "    reversed_arr = array #[::-1] # reverse array so the tif looks like the array\n",
        "    array2raster(newRasterfn, rasterOrigin, pixelWidth, pixelHeight, reversed_arr) # convert array to raster\n"
      ],
      "metadata": {
        "id": "gbo6VgF-nlLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_file_path = os.path.join(dir, city, image_file_name)"
      ],
      "metadata": {
        "id": "kkGDFq-2n3RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get metadata of original image\n",
        "image = gdal.Open(image_file_path)\n",
        "geo_transform = image.GetGeoTransform()\n",
        "originX = geo_transform[0]\n",
        "originY = geo_transform[3]\n",
        "pixelWidth = geo_transform[1]\n",
        "pixelHeight = geo_transform[5]\n"
      ],
      "metadata": {
        "id": "L0fOlPtcntLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predicted array as tiff file\n",
        "pred_file_name = 'pred_pugs.tif'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rasterOrigin = (originX, originY)\n",
        "    pixelWidth = pixelWidth\n",
        "    pixelHeight = pixelHeight\n",
        "    newRasterfn = os.path.join(dir, city, pred_file_name)  # file path you want to save\n",
        "    main(newRasterfn, rasterOrigin, pixelWidth, pixelHeight, reconstructed_image)"
      ],
      "metadata": {
        "id": "j61RDMcnoHOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "3_produce_image_output_github.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}